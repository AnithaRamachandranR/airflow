[2020-06-17 13:31:34,790] {taskinstance.py:669} INFO - Dependencies all met for <TaskInstance: S3.upload_file_to_S3 2019-01-01T00:00:00+00:00 [queued]>
[2020-06-17 13:31:34,797] {taskinstance.py:669} INFO - Dependencies all met for <TaskInstance: S3.upload_file_to_S3 2019-01-01T00:00:00+00:00 [queued]>
[2020-06-17 13:31:34,797] {taskinstance.py:879} INFO - 
--------------------------------------------------------------------------------
[2020-06-17 13:31:34,797] {taskinstance.py:880} INFO - Starting attempt 1 of 1
[2020-06-17 13:31:34,797] {taskinstance.py:881} INFO - 
--------------------------------------------------------------------------------
[2020-06-17 13:31:34,806] {taskinstance.py:900} INFO - Executing <Task(PythonOperator): upload_file_to_S3> on 2019-01-01T00:00:00+00:00
[2020-06-17 13:31:34,807] {standard_task_runner.py:53} INFO - Started process 4863 to run task
[2020-06-17 13:31:34,863] {logging_mixin.py:112} INFO - Running %s on host %s <TaskInstance: S3.upload_file_to_S3 2019-01-01T00:00:00+00:00 [running]> ip-172-31-76-14.ec2.internal
[2020-06-17 13:31:34,896] {logging_mixin.py:112} INFO - [2020-06-17 13:31:34,895] {credentials.py:1196} INFO - Found credentials in shared credentials file: ~/.aws/credentials
[2020-06-17 13:31:35,057] {taskinstance.py:1145} ERROR - Invalid endpoint: https://s3.[ec2-user@ip-172-31-76-14 dags]$ cd ...amazonaws.com
Traceback (most recent call last):
  File "/usr/lib/python2.7/site-packages/airflow/models/taskinstance.py", line 983, in _run_raw_task
    result = task_copy.execute(context=context)
  File "/usr/lib/python2.7/site-packages/airflow/operators/python_operator.py", line 113, in execute
    return_value = self.execute_callable()
  File "/usr/lib/python2.7/site-packages/airflow/operators/python_operator.py", line 118, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/home/ec2-user/airflow/dags/s3.py", line 15, in upload
    hook.load_file(filename, key, bucket_name)
  File "/usr/lib/python2.7/site-packages/airflow/hooks/S3_hook.py", line 357, in load_file
    if not replace and self.check_for_key(key, bucket_name):
  File "/usr/lib/python2.7/site-packages/airflow/hooks/S3_hook.py", line 206, in check_for_key
    self.get_conn().head_object(Bucket=bucket_name, Key=key)
  File "/usr/lib/python2.7/site-packages/airflow/hooks/S3_hook.py", line 44, in get_conn
    return self.get_client_type('s3')
  File "/usr/lib/python2.7/site-packages/airflow/contrib/hooks/aws_hook.py", line 179, in get_client_type
    config=config, verify=self.verify)
  File "/home/ec2-user/.local/lib/python2.7/site-packages/boto3/session.py", line 263, in client
    aws_session_token=aws_session_token, config=config)
  File "/home/ec2-user/.local/lib/python2.7/site-packages/botocore/session.py", line 835, in create_client
    client_config=config, api_version=api_version)
  File "/home/ec2-user/.local/lib/python2.7/site-packages/botocore/client.py", line 85, in create_client
    verify, credentials, scoped_config, client_config, endpoint_bridge)
  File "/home/ec2-user/.local/lib/python2.7/site-packages/botocore/client.py", line 287, in _get_client_args
    verify, credentials, scoped_config, client_config, endpoint_bridge)
  File "/home/ec2-user/.local/lib/python2.7/site-packages/botocore/args.py", line 107, in get_client_args
    client_cert=new_config.client_cert)
  File "/home/ec2-user/.local/lib/python2.7/site-packages/botocore/endpoint.py", line 286, in create_endpoint
    raise ValueError("Invalid endpoint: %s" % endpoint_url)
ValueError: Invalid endpoint: https://s3.[ec2-user@ip-172-31-76-14 dags]$ cd ...amazonaws.com
[2020-06-17 13:31:35,067] {taskinstance.py:1202} INFO - Marking task as FAILED.dag_id=S3, task_id=upload_file_to_S3, execution_date=20190101T000000, start_date=20200617T133134, end_date=20200617T133135
[2020-06-17 13:31:44,788] {logging_mixin.py:112} INFO - [2020-06-17 13:31:44,788] {local_task_job.py:103} INFO - Task exited with return code 1
